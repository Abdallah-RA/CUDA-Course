{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO7Nzssoq4wWeRYY7h4we+C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abdallah-RA/CUDA-Course/blob/main/CUDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYrYjFmzl3VF",
        "outputId": "60f83d29-1bf5-47b0-8741-65573f6205e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Mar 31 08:21:27 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n",
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile hello.cu\n",
        "#include <iostream>\n",
        "#include <cstdio>         // for printf in the kernel\n",
        "#include <cuda_runtime.h> // for cuda functions\n",
        "\n",
        "// Simple kernel that prints from the GPU\n",
        "__global__ void helloFromGPU() {\n",
        "    if (threadIdx.x == 0 && blockIdx.x == 0) {\n",
        "        printf(\"Hello World from GPU!\\n\");\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // Launch the kernel (1 block, 1 thread)\n",
        "    helloFromGPU<<<1, 1>>>();\n",
        "\n",
        "    // Check for any errors during kernel launch\n",
        "    cudaError_t err = cudaGetLastError();\n",
        "    if (err != cudaSuccess) {\n",
        "        std::cerr << \"Kernel launch error: \"\n",
        "                  << cudaGetErrorString(err) << std::endl;\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    // Wait for GPU to finish, ensures the kernel's printf completes\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Print from the CPU\n",
        "    std::cout << \"Hello from CPU!\" << std::endl;\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDFKtf6tmfsE",
        "outputId": "84dccf36-841c-4009-fa89-1767ebed0b5c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing hello.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 hello.cu -o hello"
      ],
      "metadata": {
        "id": "Zx12yVclmmEg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./hello\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMAHjNe4mp1L",
        "outputId": "44283595-c42c-44da-ef8a-12b793720a89"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World from GPU!\n",
            "Hello from CPU!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile Code1.cu\n",
        "#include <iostream>\n",
        "#include <cstdio>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__host__ int hostOnlyFunction(int x) {\n",
        "    return x * 2;\n",
        "}\n",
        "\n",
        "__device__ int deviceOnlyFunction(int x) {\n",
        "    return x + 1;\n",
        "}\n",
        "\n",
        "\n",
        "__global__ void computeOnGPU(int* dArray, int N) {\n",
        "    int idx = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    if (idx < N) {\n",
        "        dArray[idx] = deviceOnlyFunction(idx);\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    cudaError_t err;\n",
        "\n",
        "    const int N = 5;\n",
        "    int hArray[N];      // host array\n",
        "    int *dArray = nullptr;  // device pointer\n",
        "\n",
        "    cudaMalloc((void**)&dArray, N * sizeof(int));\n",
        "\n",
        "    computeOnGPU<<<1, N>>>(dArray, N);\n",
        "    err = cudaGetLastError();\n",
        "    if (err != cudaSuccess) {\n",
        "        std::cerr << \"Kernel (computeOnGPU) launch error: \"\n",
        "                  << cudaGetErrorString(err) << std::endl;\n",
        "        return 1;\n",
        "    }\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    cudaMemcpy(hArray, dArray, N * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    std::cout << \"\\nResults from computeOnGPU (with deviceOnlyFunction):\\n\";\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        int doubledVal = hostOnlyFunction(hArray[i]); // __host__ function\n",
        "        std::cout << \"Index \" << i\n",
        "                  << \" => GPU value: \" << hArray[i]\n",
        "                  << \", hostOnlyFunction result: \" << doubledVal\n",
        "                  << std::endl;\n",
        "    }\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(dArray);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDqnYmQBRrIJ",
        "outputId": "1db99850-3aaf-46e6-c3e9-29b9dc2f336b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting Code1.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 Code1.cu -o Code1\n",
        "!./Code1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-QoUqghSb5l",
        "outputId": "a144f1a8-a207-47f9-979d-647641aa03eb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello from CPU!\n",
            "\n",
            "Results from computeOnGPU (with deviceOnlyFunction):\n",
            "Index 0 => GPU value: 1, hostOnlyFunction result: 2\n",
            "Index 1 => GPU value: 2, hostOnlyFunction result: 4\n",
            "Index 2 => GPU value: 3, hostOnlyFunction result: 6\n",
            "Index 3 => GPU value: 4, hostOnlyFunction result: 8\n",
            "Index 4 => GPU value: 5, hostOnlyFunction result: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile multiDimKernels.cu\n",
        "#include <iostream>\n",
        "#include <cstdio>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// ------------------------------\n",
        "// 1D Kernel\n",
        "// ------------------------------\n",
        "__global__ void fillArray1D(int* dArr, int N) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < N) {\n",
        "        // Just store the thread index in the array\n",
        "        dArr[idx] = idx;\n",
        "    }\n",
        "}\n",
        "\n",
        "// ------------------------------\n",
        "// 2D Kernel\n",
        "// ------------------------------\n",
        "__global__ void fillArray2D(int* dArr, int width, int height) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // Check boundary\n",
        "    if (row < height && col < width) {\n",
        "        // Flatten 2D (row, col) into a 1D index\n",
        "        int idx = row * width + col;\n",
        "        // Example: store row*100 + col\n",
        "        dArr[idx] = row * 100 + col;\n",
        "    }\n",
        "}\n",
        "\n",
        "// ------------------------------\n",
        "// 3D Kernel\n",
        "// ------------------------------\n",
        "__global__ void fillArray3D(int* dArr, int width, int height, int depth) {\n",
        "    int x = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int y = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int z = blockIdx.z * blockDim.z + threadIdx.z;\n",
        "\n",
        "    if (x < width && y < height && z < depth) {\n",
        "        // Flatten 3D (x, y, z) into 1D index: z*(width*height) + y*width + x\n",
        "        int idx = z * (width * height) + y * width + x;\n",
        "        // Example: store x + 10*y + 100*z\n",
        "        dArr[idx] = x + 10 * y + 100 * z;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // --------------------------------\n",
        "    // 1) 1D Example\n",
        "    // --------------------------------\n",
        "    {\n",
        "        std::cout << \"=== 1D Example ===\\n\";\n",
        "        const int N = 8;\n",
        "        int size1D = N * sizeof(int);\n",
        "\n",
        "        // Allocate host memory\n",
        "        int* hArr1D = (int*)malloc(size1D);\n",
        "\n",
        "        // Allocate device memory\n",
        "        int* dArr1D;\n",
        "        cudaMalloc(&dArr1D, size1D);\n",
        "\n",
        "        // Calculate block / grid\n",
        "        int threads = 4;          // let's choose 4 threads\n",
        "        int blocks  = (N + threads - 1) / threads;\n",
        "\n",
        "        // Launch kernel\n",
        "        fillArray1D<<<blocks, threads>>>(dArr1D, N);\n",
        "        cudaDeviceSynchronize();\n",
        "\n",
        "        // Copy back\n",
        "        cudaMemcpy(hArr1D, dArr1D, size1D, cudaMemcpyDeviceToHost);\n",
        "\n",
        "        // Print entire 1D array\n",
        "        std::cout << \"1D array contents:\\n\";\n",
        "        for (int i = 0; i < N; i++) {\n",
        "            std::cout << \"hArr1D[\" << i << \"] = \" << hArr1D[i] << \"\\n\";\n",
        "        }\n",
        "\n",
        "        // Cleanup\n",
        "        free(hArr1D);\n",
        "        cudaFree(dArr1D);\n",
        "    }\n",
        "\n",
        "    // --------------------------------\n",
        "    // 2) 2D Example\n",
        "    // --------------------------------\n",
        "    {\n",
        "        std::cout << \"\\n=== 2D Example ===\\n\";\n",
        "        int width  = 4;\n",
        "        int height = 3;  // total = 12 elements\n",
        "        int size2D = width * height * sizeof(int);\n",
        "\n",
        "        int* hArr2D = (int*)malloc(size2D);\n",
        "        int* dArr2D;\n",
        "        cudaMalloc(&dArr2D, size2D);\n",
        "\n",
        "        // 2D thread-block, 2D grid\n",
        "        dim3 block2D(2, 2);  // 2x2 threads\n",
        "        dim3 grid2D( (width  + block2D.x - 1)/block2D.x,\n",
        "                     (height + block2D.y - 1)/block2D.y );\n",
        "\n",
        "        // Launch 2D kernel\n",
        "        fillArray2D<<<grid2D, block2D>>>(dArr2D, width, height);\n",
        "        cudaDeviceSynchronize();\n",
        "\n",
        "        // Copy results\n",
        "        cudaMemcpy(hArr2D, dArr2D, size2D, cudaMemcpyDeviceToHost);\n",
        "\n",
        "        // Print the entire 2D array in row-major format\n",
        "        std::cout << \"2D array contents (row-major):\\n\";\n",
        "        for (int r = 0; r < height; r++) {\n",
        "            for (int c = 0; c < width; c++) {\n",
        "                int idx = r * width + c;\n",
        "                std::cout << hArr2D[idx] << \"\\t\";\n",
        "            }\n",
        "            std::cout << \"\\n\";\n",
        "        }\n",
        "\n",
        "        // Cleanup\n",
        "        free(hArr2D);\n",
        "        cudaFree(dArr2D);\n",
        "    }\n",
        "\n",
        "    // --------------------------------\n",
        "    // 3) 3D Example\n",
        "    // --------------------------------\n",
        "    {\n",
        "        std::cout << \"\\n=== 3D Example ===\\n\";\n",
        "        int width  = 3;\n",
        "        int height = 2;\n",
        "        int depth  = 2;  // total = 3*2*2 = 12 elements\n",
        "        int size3D = width * height * depth * sizeof(int);\n",
        "\n",
        "        int* hArr3D = (int*)malloc(size3D);\n",
        "        int* dArr3D;\n",
        "        cudaMalloc(&dArr3D, size3D);\n",
        "\n",
        "        // 3D block / grid\n",
        "        dim3 block3D(2, 2, 1);\n",
        "        dim3 grid3D( (width  + block3D.x - 1)/block3D.x,\n",
        "                     (height + block3D.y - 1)/block3D.y,\n",
        "                     (depth  + block3D.z - 1)/block3D.z );\n",
        "\n",
        "        // Launch 3D kernel\n",
        "        fillArray3D<<<grid3D, block3D>>>(dArr3D, width, height, depth);\n",
        "        cudaDeviceSynchronize();\n",
        "\n",
        "        // Copy back\n",
        "        cudaMemcpy(hArr3D, dArr3D, size3D, cudaMemcpyDeviceToHost);\n",
        "\n",
        "        // Print 3D data layer by layer\n",
        "        std::cout << \"3D array contents (z-layers, row-major within each layer):\\n\";\n",
        "        for (int z = 0; z < depth; z++) {\n",
        "            std::cout << \"Layer z=\" << z << \":\\n\";\n",
        "            for (int y = 0; y < height; y++) {\n",
        "                for (int x = 0; x < width; x++) {\n",
        "                    int idx = z * (width * height) + y * width + x;\n",
        "                    std::cout << hArr3D[idx] << \"\\t\";\n",
        "                }\n",
        "                std::cout << \"\\n\";\n",
        "            }\n",
        "            std::cout << \"\\n\";\n",
        "        }\n",
        "\n",
        "        // Cleanup\n",
        "        free(hArr3D);\n",
        "        cudaFree(dArr3D);\n",
        "    }\n",
        "\n",
        "    std::cout << \"\\nDone.\\n\";\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1KI71TlW8cU",
        "outputId": "8e2a16c1-b24b-498f-db59-4321281358a1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing multiDimKernels.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 multiDimKernels.cu -o multiDim\n",
        "!./multiDim\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lw4GwO4XAp5",
        "outputId": "9b329c19-fa91-4bfd-b723-cf60df10425c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== 1D Example ===\n",
            "1D array contents:\n",
            "hArr1D[0] = 0\n",
            "hArr1D[1] = 1\n",
            "hArr1D[2] = 2\n",
            "hArr1D[3] = 3\n",
            "hArr1D[4] = 4\n",
            "hArr1D[5] = 5\n",
            "hArr1D[6] = 6\n",
            "hArr1D[7] = 7\n",
            "\n",
            "=== 2D Example ===\n",
            "2D array contents (row-major):\n",
            "0\t1\t2\t3\t\n",
            "100\t101\t102\t103\t\n",
            "200\t201\t202\t203\t\n",
            "\n",
            "=== 3D Example ===\n",
            "3D array contents (z-layers, row-major within each layer):\n",
            "Layer z=0:\n",
            "0\t1\t2\t\n",
            "10\t11\t12\t\n",
            "\n",
            "Layer z=1:\n",
            "100\t101\t102\t\n",
            "110\t111\t112\t\n",
            "\n",
            "\n",
            "Done.\n"
          ]
        }
      ]
    }
  ]
}